% コンパイル方法: lualatex filename.tex
\documentclass[a4paper,11pt]{article}

% マージン設定
\usepackage[top=15mm,bottom=25mm,left=20mm,right=20mm]{geometry}

% LuaLaTeX用日本語対応パッケージ
\usepackage{luatexja}
\usepackage{luatexja-fontspec}

% 必要なパッケージ
\usepackage{fontspec}
\usepackage{titlesec}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage[english,japanese]{babel}
\usepackage{multicol} % 二段組用パッケージ
\usepackage{indentfirst}
\usepackage{tikz} % カスタム点線用
\usepackage{authblk} % 著者・所属パッケージ

% フォント設定
\newjfontfamily\TitleJFont{BIZ UDPGothic}[BoldFont=BIZ UDPGothicBold]
\newjfontfamily\SectionJFont{BIZ UDPGothic}[BoldFont=BIZ UDPGothicBold]

% セクション見出しのカスタマイズ
\titleformat{\section}
  {\large\bfseries\SectionJFont}
  {\thesection}
  {1em}{}

% customabstract 環境を定義
\newenvironment{customabstract}
{\noindent\hfuzz=10pt\hbadness=10000\begin{flushleft}\small}
{\end{flushleft}}

% タイトル情報
\title{{\TitleJFont\bfseries 感情分析と時系列モデルを統合した\\データ駆動型予測システムの開発 \\ ーPBL科目実践紹介ー}}

% 著者と所属のカスタマイズ
\renewcommand\Authfont{\large\TitleJFont\bfseries} % 著者のフォント
\renewcommand\Affilfont{\large\TitleJFont\bfseries} % 所属のフォント
\setlength{\affilsep}{1em} % 所属と名前の間隔を調整

\author[1]{〇下沢 亮太郎}
\affil[1]{東京都立産業技術高等専門学校\\ものづくり工学科 情報通信工学コース}

\date{}

\titlespacing*{\section}{0pt}{8pt}{5pt}

\begin{document}

\setlength{\columnsep}{20pt}

\twocolumn[
    \maketitle

    \thispagestyle{empty}

    \vspace{-2em}
    \begin{customabstract}
    　キーワード : 機械学習 時系列予測 感情分析 BERT LSTM
    \end{customabstract}
]

\section{緒言}

都立産技高専荒川キャンパスでは,選抜された3～5年生を対象に,IoT/AI技術を学習する未来工学教育プログラムを実施している.5年生のPBL(Project Based Learning)科目では,学生たちの自由な発想を基に,学習した知見や技術を利用してアイデア実装に挑戦している.本報告では,PBL科目で取り組んだ内容について紹介する.

社会的な事象に影響を与えることが多いのは文字列や映像なことが多いという事実に対して有名な時系列予測モデルは入力に数値しかとらないことが多い.

そこで,本研究ではニュースの文章をBERTという自然言語に特化した分類モデルが出力した値を「感情らしさ」として採用し,よく使われる指標とともに時系列予測に特化したLSTMという機械学習モデルで学習し,予測した.

\section{BERTの転移学習}
BERT(Bidirectional Encoder Representations from Transformers)はGoogleによって事前学習されたモデルをクライアント側で用意したデータセットで転移学習(Fine-tuning)することで任意の形式で出力するモデルを作ることができる.

ChatGPTで作成した存在しない企業のニュースとそれに応じた失望,楽観,懸念,興奮,安定の5つのパラメータに点数を振ったデータセットを作成し,転移学習を行った.

転移学習を行ったBERTモデルの推論例を表1に示す.プラスの文章として,「【速報】世界が注目するMVIDIAが決算発表「最終的な利益 前年比7.3倍2兆3300億円」勢い止まらず」,マイナスの文章として「UUスチール買収計画が窮地に　鉄鉄、訴訟も視野」という架空のニュースを推論した.プラスの文章では楽観と興奮,マイナスの文章では懸念と失望が高く出ていることから目標とした傾向を持っているモデルを作ることができたと考えられる.

\begin{table}[htbp]
    \centering
    \begin{tabular}{|c|c|c|c|c|}\hline
        \multicolumn{5}{|c|}{プラスの文章} \\ \hline
        失望 & 楽観 & 懸念 & 興奮 & 安定 \\ \hline
        0.0534 & 0.395 & 0.109 & 0.231 & 0.212 \\ \hline
        \multicolumn{5}{|c|}{マイナスの文章} \\ \hline
        失望 & 楽観 & 懸念 & 興奮 & 安定 \\ \hline
        0.254 & 0.110 & 0.351 & 0.135 & 0.150 \\ \hline
    \end{tabular}

    \caption{推論結果例}

\end{table}





\section{結言}
ご質問がありましたら以下にご連絡ください。

% カスタム点線を描画
\noindent
\begin{tikzpicture}
\draw[dotted, thick] (0,0) -- (\linewidth,0);
\end{tikzpicture}
お問い合わせ先\\
氏名：高田 拓 \\
E-mail : \href{mailto:takada@metro-cit.ac.jp}{takada@metro-cit.ac.jp}

\end{document}
